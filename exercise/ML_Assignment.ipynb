{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qottmann/anaconda3/envs/test/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Implement a function that computes the forward pass for the fixed weights `w` and bias `b` provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix weights: [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31]\n",
      " [ 32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49\n",
      "   50  51  52  53  54  55  56  57  58  59  60  61  62  63]\n",
      " [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "   82  83  84  85  86  87  88  89  90  91  92  93  94  95]\n",
      " [ 96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      "  114 115 116 117 118 119 120 121 122 123 124 125 126 127]\n",
      " [128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      "  146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
      " [160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177\n",
      "  178 179 180 181 182 183 184 185 186 187 188 189 190 191]\n",
      " [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      "  210 211 212 213 214 215 216 217 218 219 220 221 222 223]\n",
      " [224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241\n",
      "  242 243 244 245 246 247 248 249 250 251 252 253 254 255]\n",
      " [256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      "  274 275 276 277 278 279 280 281 282 283 284 285 286 287]\n",
      " [288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      "  306 307 308 309 310 311 312 313 314 315 316 317 318 319]]\n",
      "fix bias: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Fix weight matrix for better comparison\n",
    "w = np.arange(32*10).reshape(10, 32)\n",
    "# Fix bias\n",
    "b = np.arange(10)\n",
    "print(f\"fix weights: {w}\")\n",
    "print(f\"fix bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison and to check if your solution is right, you can use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_ex1(x):\n",
    "    \"\"\"\n",
    "    This function performs the task of exercise 1\n",
    "    You can use it to test whether \n",
    "    \"\"\"\n",
    "    # Creating a linear layer with pytorch\n",
    "    linear = torch.nn.Linear(32, 10)\n",
    "    # This is a bit ugly because a) you are not supposed to set the weights fixed from outside,\n",
    "    # and b) because we convert numpy arrays to pytorch tensors with the correct dtype\n",
    "    linear.bias = nn.Parameter(torch.tensor(b, dtype=torch.float))\n",
    "    linear.weight = nn.Parameter(torch.tensor(w, dtype=torch.float))\n",
    "    relu = torch.nn.ReLU()\n",
    "\n",
    "    # Processing input\n",
    "    x = x[np.newaxis] # Need to create dummy dimension for batch_size; alternative: reshape, or fancy indexing: x=x[None]\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    z = linear(x)\n",
    "    a = relu(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 258.3965,  817.7271, 1377.0575, 1936.3882, 2495.7185, 3055.0493,\n",
       "         3614.3796, 4173.7100, 4733.0405, 5292.3711]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(32)\n",
    "\n",
    "func_ex1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex1.2: Combine the function of Ex. 1 multiple times with 3 fixed weight matrices of your choosing. Be careful to make sure that input and output dimensions match for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex1.3 (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex2: Implement a function that performs the convolutional layer forward pass for 1 fixed filter w and for the given input x. Use stride 1 and no padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20) # some input\n",
    "w = np.array([1,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex2.2: Generalize the above function to handle multiple filters (i.e. the same convolutional layer but with 3 filters leading to 3 output channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20) # some input\n",
    "w1 = np.array([1,0,1])\n",
    "w2 = np.array([1,2,3])\n",
    "w3 = np.array([5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex2.3: Generalize the above function to handle variable padding and stride. Test it for stride 2 and padding 2.  \n",
    "In case you did not manage to generalize to 3 filters, do it for the version of ex.2.1 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20) # some input\n",
    "w1 = np.array([1,0,1])\n",
    "w2 = np.array([1,2,3])\n",
    "w3 = np.array([5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex3 (extra): Combine the function from the previous exercises to a full forward pass consisting of 2 convolutional layers, flatten, and then 2 fully connected layers to output a probability vector of size 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c14f2b6c53c1215ff3f99a16ef8c62db922d1bf174e6cecc764d47c60aae3936"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
