{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2022/blob/master/03_Stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqAIqBlSmD4w"
   },
   "source": [
    "# Session 3 - Statistics in Python (First part - 30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A very basic introduction on statistics in Python. In this first introductory lesson we will just present some *Measures of Central Tendency* (median, mean and weighted mean) and *Measures of Variability* (variance and standard deviation). We will also talk about *Percentiles* and *Missing values*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " * [Measures of Central Tendency](#Measures-of-Central-Tendency)\n",
    "   * [Median](#Median)\n",
    "   * [Mean](#Mean)\n",
    "   * [Weighted mean](#Weighted-mean) \n",
    " * [Measures of Variability](#Measures-of-Variability)\n",
    "   * [Variance](#Variance)\n",
    "   * [Standard deviation](#Standard-deviation)\n",
    " * [Percentiles](#Percentiles)\n",
    " * [Missing values](#Missing-values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is devised as a tool to enable your **self-learning process**. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance. Along it, you will find some **special cells**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session. Usually, solutions are provided using hidden cells (look for the dot dot dot symbol \"...\" and unravel it by clicking to check that your try is correct). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Tip cells just give some advice or complementary information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this very basic introduction on statistics in Python we will leverage some NumPy functions. Let's import this package with its typical alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86WqXweTk9Jh"
   },
   "outputs": [],
   "source": [
    "# Load package with its corresponding alias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We will devote a whole boot camp session to NumPy on October 5<sup>th</sup> (10:00-11:00). </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTTVyKXslupX"
   },
   "source": [
    "# Measures of Central Tendency\n",
    "\n",
    "The measures of central tendency show the central or middle values of data sets. There are several definitions of what's considered to be the center of a data set. In this tutorial, you'll learn how to identify and calculate these measures of central tendency. Let's create a list with some arbitrary values to work with along the upcoming sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with some floats and integers\n",
    "x = [8.0, 1, 2.5, 4, 28.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svQtQ0aEmgWU",
    "tags": []
   },
   "source": [
    "## Median\n",
    "\n",
    "The sample median is the middle element of a sorted dataset. We can compute the median using the NumPy function [`np.median()`](https://numpy.org/doc/stable/reference/generated/numpy.median.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU89gVremmSl",
    "outputId": "f6897dad-1771-4160-f6d4-5c354d84a597"
   },
   "outputs": [],
   "source": [
    "# Compute the median of \"x\"\n",
    "x_median = np.median(x)\n",
    "\n",
    "# Return \"x_median\"\n",
    "print(x_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the middle element of the sorted `x` list is precisely `4`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list with arbitrary values called x\n",
    "sorted(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "The sample mean (also called the sample arithmetic mean or simply the average) of a collection of values, $\\bar{x}$, is defined as follows:\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{N}\\sum^{N}_{i=1}{x_i}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection and $N$ the number of elements comprising such collection. You have already seen that you can calculate the mean using the Python built-ins `sum()` and `len()`, without importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LnbFPQplR--",
    "outputId": "ed07a231-1a32-4a40-a13c-1b8d5f1e1329"
   },
   "outputs": [],
   "source": [
    "# Compute and store the mean of \"x\" in \"x_mean_builtin\"\n",
    "x_mean_builtin = sum(x) / len(x)\n",
    "\n",
    "# Return \"x_mean_builtin\"\n",
    "print(x_mean_builtin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively use the NumPy function [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DDg71BHlZ_I",
    "outputId": "64f2949b-678f-4863-d179-41c56bc20df4"
   },
   "outputs": [],
   "source": [
    "# Compute and store the mean of \"x\" in \"x_mean\"\n",
    "x_mean = np.mean(x)\n",
    "\n",
    "# Return \"x_mean\"\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS88kTWll_Qw"
   },
   "source": [
    "## Weighted mean\n",
    "\n",
    "The weighted mean (also called the weighted arithmetic mean or weighted average) of a collection of values, $\\bar{x}_{w}$, is a generalization of the mean that enables you to define the relative contribution of each value to the result:\n",
    "\n",
    "$$\\bar{x}_{w} = \\frac{\\sum^{N}_{i=1}{x_i w_i}}{\\sum^{N}_{i=1}{w_i}}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, $w_i$ its weight, and $N$ the number of elements comprising such collection. The weighted mean is very handy when you need the mean of a data set containing items that occur with given relative frequencies. For example, remember the values stored in our list `x`, say that you have a collection of values in which 60 % of all items are equal to `8.0`, 20 % are equal to `1`, 10 % are equal to `2.5`, 8 % are equal to `4` and 2 % are equal to `28.0`. You can calculate the mean of such a collection using the NumPy function [`np.average()`](https://numpy.org/doc/stable/reference/generated/numpy.average.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZqCpAWpls1t",
    "outputId": "b1fb159a-6e0f-42c7-dc6d-16c20c880215"
   },
   "outputs": [],
   "source": [
    "# Create a list of weights for the values stored in \"x\"\n",
    "w = [0.60, 0.20, 0.10, 0.08, 0.02]\n",
    "\n",
    "# Compute and store the weighted mean in \"x_weighted_mean\" and the regular mean in \"x_mean\"\n",
    "x_weighted_mean = np.average(x, weights=w)\n",
    "x_mean = np.average(x)\n",
    "\n",
    "# Return \"x_weighted_mean\" and \"x_mean\"\n",
    "print(x_weighted_mean)\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"regular\" mean is a particular case of weighted mean on which all weights are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDzxAsrumtqT"
   },
   "source": [
    "# Measures of Variability\n",
    "\n",
    "The measures of central tendency aren't sufficient to describe data. You'll also need the measures of variability that quantify the spread of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "The variance of a collection of values, $\\sigma^2$, is defined as follows:\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{N-1}\\sum^{N}_{i=1}{\\left(x_i - \\bar{x}\\right)^2}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, and $N$ and  $\\bar{x}$ are the number of elements and the mean of such collection, respectively. The variance quantifies the spread of the data. It shows numerically how far the values are from the mean. As usual, NumPy has a function for this purpose called [`np.var()`](https://numpy.org/doc/stable/reference/generated/numpy.var.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNv4Ej79mp24",
    "outputId": "0a607e86-9e58-4064-8089-1b82820322dd"
   },
   "outputs": [],
   "source": [
    "# Compute and store the (biased) sample variance of \"x\" in \"x_var_bias\"\n",
    "x_var_bias = np.var(x, ddof=0)\n",
    "\n",
    "# Compute and store the (unbiased) sample variance of \"x\" in \"x_var_unbias\"\n",
    "x_var_unbias = np.var(x, ddof=1)\n",
    "\n",
    "# Return \"x_var_bias\" and \"x_var_unbias\"\n",
    "print(x_var_bias)\n",
    "print(x_var_unbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, [`np.var()`](https://numpy.org/doc/stable/reference/generated/numpy.var.html) uses `ddof=0` (Delta Degrees of Freedom), which gives the *biased sample variance*. By changing `ddof=1` you get the *unbiased sample variance* (AKA [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)). From now on, we will use the *unbiased sample variance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb7KAv_zm2_C"
   },
   "source": [
    "## Standard deviation\n",
    "\n",
    "The standard deviation, $\\sigma$, is defined as follows:\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{N-1}\\sum^{N}_{i=1}{\\left(x_i - \\bar{x}\\right)^2}}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, and $N$ and  $\\bar{x}$ are the number of elements and the mean of such collection, respectively. The standard deviation is another measure of data spread which is often more convenient than the variance because it has the same dimensionality (units) as its associated values. You can compute the standard deviation just by taking the square root of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S47vO1HnJfET"
   },
   "outputs": [],
   "source": [
    "# Compute and store the variance of \"x\" in \"x_var\"\n",
    "x_var = np.var(x, ddof=1)\n",
    "\n",
    "# Compute and store the standard deviation of \"x\" in \"x_std\"\n",
    "x_std = np.sqrt(x_var)\n",
    "\n",
    "# Return \"x_std\"\n",
    "print(x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the NumPy function [`np.std()`](https://numpy.org/doc/stable/reference/generated/numpy.std.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the standard deviation of \"x\" in \"x_std\"\n",
    "x_std = np.std(x, ddof=1)\n",
    "\n",
    "# Return \"x_std\"\n",
    "print(x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbCvXLHEJsnn"
   },
   "source": [
    "# Percentiles\n",
    "\n",
    "Percentiles are used to express where a value falls in a range of other values. It's as if it were a competition of values: the 100<sup>th</sup> percentile is the top value of the collection (largest), the 0<sup>th</sup> percentile is the bottom value of the collection (smallest), the 85<sup>th</sup> percentile is the value having 85 % of the values of the collection behind and 15 % in front, and so on. The NumPy function to get your percentiles is [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html). For example, let's say we have an array of the ages of all the people that lives in a village:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43YBIOfQJoJF",
    "outputId": "6d23470f-c8e0-40c8-c3e7-982ad36a8960"
   },
   "outputs": [],
   "source": [
    "# Create list with some ages\n",
    "ages = [5, 31, 43, 48, 50, 41, 7, 11, 15, 39, 80, 82, 32, 2, 8, 6, 25, 36, 27, 61, 31]\n",
    "\n",
    "# Compute the percentile 75 of \"ages\"\n",
    "ages_75 = np.percentile(ages, 75)\n",
    "\n",
    "# Return \"ages_75\"\n",
    "print(ages_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 50<sup>th</sup> percentile is just the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the percentile 50 equals the median\n",
    "np.percentile(ages, 50) == np.median(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> When one says that a journal is in the \"first quartile\", it just means that only 25 % of the journals are scored in front of it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, box plots represent five percentiles: 5 (bottom whisker), 25 (box bottom edge), 50 (mid box), 75 (box top edge) and 95 (top whisker):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH--LP6vJ1X2",
    "outputId": "c76a8f7d-dd15-4b23-e1f2-b7d3b94d776f"
   },
   "outputs": [],
   "source": [
    "# Compute the five typical percentiles of \"ages\"\n",
    "np.percentile(ages, [5, 25, 50, 75, 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load plotting package seaborn with its corresponding alias\n",
    "import seaborn as sns\n",
    "\n",
    "# Get box plot for \"ages\"\n",
    "sns.boxplot(y=ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We will devote a whole boot camp session to Seaborn on September 21 <sup>st</sup> (11:00-12:00).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "In many scientific disciplines it is very common to deal with \"value holes\" (or *missing values*) when analyzing your data. In Python, missing values are represented as `nan`, which stands for \"Not a Number\". The NumPy package offers a very efficient implementation `nan` values for Python. Note that Python treats `nan`s as floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable type of a nan\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outcome of involving a nan in an arithmetic operation\n",
    "print(np.nan + 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you should proceed with caution when computing descriptive statistics of data sets containing missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1:</b>\n",
    "\n",
    "1) In the 1<sup>st</sup> code cell below, check if the mean and the median of `[1, 2, 3, 4, 5, 6]` are equal to the mean and the median of `[np.nan, 1, 2, 3, 4, 5, 6]`, respectively:\n",
    "    \n",
    "2) In the 2<sup>nd</sup> code cell below, do the same as before with the functions [`np.nanmean()`](https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html) instead of [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) and [`np.nanmedian()`](https://numpy.org/doc/stable/reference/generated/numpy.nanmedian.html) instead of [`np.median()`](https://numpy.org/doc/stable/reference/generated/numpy.median.html)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and the median of a dice\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean and the median of a dice containing a nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the mean and the median of a dice\n",
    "print(np.mean([1, 2, 3, 4, 5, 6]))\n",
    "print(np.median([1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "# Compute the mean and the median of a dice containing a nan\n",
    "print(np.mean([np.nan, 1, 2, 3, 4, 5, 6]))\n",
    "print(np.median([np.nan, 1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the nanmean and the nanmedian of a dice\n",
    "\n",
    "\n",
    "\n",
    "# Compute the nanmean and the nanmedian of a dice containing a nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the nanmean and the nanmedian of a dice\n",
    "print(np.nanmean([1, 2, 3, 4, 5, 6]))\n",
    "print(np.nanmedian([1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "# Compute the nanmean and the nanmedian of a dice containing a nan\n",
    "print(np.nanmean([np.nan, 1, 2, 3, 4, 5, 6]))\n",
    "print(np.nanmedian([np.nan, 1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `nan` values are not automatically dropped when doing arithmetic computations with NumPy. Some functions (like of `np.mean()` and `np.median()`) try to keep `nan` values, only being able to return a `nan` at the end of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b>\n",
    "\n",
    "Dealing with missing values is tricky and usually needs *data imputation* because advanced statistical analyses (like differential gene expression/protein abundance analysis or machine learning) require complete data (with no missing values). Not all data sets can be imputed in the same way so there is no a \"best imputation algorithm\".\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzEHUEKWP4G0lHcKMGoPob",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "07_scipy_stats.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
